// Exemplo de treinamento com detecÃ§Ã£o automÃ¡tica de RayPerception
use rl_core::trainers::sac::{SACTrainer, SACConfig, ObservationSpec};
use tch::Device;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ® SAC Training with Unity - RayPerception Auto-Detection");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
    
    // ConfiguraÃ§Ã£o
    let config = SACConfig {
        hidden_layers: vec![256, 256],
        checkpoint_interval: 10000,
        save_onnx: true,
        ..Default::default()
    };
    
    let device = Device::cuda_if_available();
    println!("ğŸ–¥ï¸  Device: {:?}\n", device);
    
    // Nota: DimensÃµes serÃ£o detectadas automaticamente do Unity
    println!("ğŸ” Waiting for Unity connection...");
    println!("   (Start Unity with your ML-Agents scene)\n");
    
    // Simular primeira observaÃ§Ã£o do Unity
    // Em produÃ§Ã£o, isso virÃ¡ da conexÃ£o real
    println!("ğŸ“¡ Simulating Unity observations for demo...\n");
    
    // Exemplo 1: Apenas Vector Observations
    let vector_only = vec![vec![0.5; 62]];
    let spec1 = ObservationSpec::detect_from_observations(&vector_only);
    spec1.print_info();
    
    println!("\n{}", "â”€".repeat(64));
    println!("\nğŸ”„ Now simulating with RayPerception...\n");
    
    // Exemplo 2: Vector + RayPerception
    let vector_with_ray = vec![
        vec![0.5; 62],   // Vector observations
        vec![0.3; 100],  // RayPerception sensor
    ];
    let spec2 = ObservationSpec::detect_from_observations(&vector_with_ray);
    spec2.print_info();
    
    // Criar modelo com dimensÃµes corretas
    let obs_dim = spec2.total_obs_size as i64;
    let action_dim = 2i64;
    
    println!("ğŸ¤– Creating SAC model with detected dimensions...");
    println!("   â””â”€ obs_dim: {}", obs_dim);
    println!("   â””â”€ action_dim: {}", action_dim);
    println!("   â””â”€ hidden_dim: {:?}", config.hidden_layers);
    
    let mut trainer = SACTrainer::new(
        obs_dim,
        action_dim,
        config.clone(),
        device,
    )?;
    
    println!("\nâœ… Model created successfully!");
    println!("\nğŸ’¡ In production, connect to Unity:");
    println!("   1. Start Unity with ML-Agents scene");
    println!("   2. Run: cargo run --example train_with_unity");
    println!("   3. System will auto-detect sensors");
    println!("   4. Training starts with correct dimensions\n");
    
    // Salvar checkpoint de exemplo
    println!("ğŸ’¾ Saving example checkpoint...");
    trainer.save_checkpoint("results/rayperception_example.pt")?;
    
    println!("âœ… Checkpoint saved!");
    println!("   â””â”€ Model: results/rayperception_example.pt");
    println!("   â””â”€ Metadata: results/metadata.json");
    println!("      (Contains obs_dim={}, action_dim={})\n", obs_dim, action_dim);
    
    // Exportar ONNX
    if config.save_onnx {
        println!("ğŸ“¦ Exporting ONNX...");
        trainer.export_onnx("results/rayperception_example")?;
        println!("âœ… ONNX exported!");
        println!("   â””â”€ File: results/rayperception_example.onnx");
        println!("   â””â”€ Input shape: [batch, {}]", obs_dim);
        println!("   â””â”€ Output shape: [batch, {}]\n", action_dim);
    }
    
    println!("ğŸ‰ Demo completed!");
    println!("\nğŸ“š Next steps:");
    println!("   1. Check RAYPERCEPTION_DETECTION.md for details");
    println!("   2. Configure your Unity Agent");
    println!("   3. Start real training\n");
    
    Ok(())
}
